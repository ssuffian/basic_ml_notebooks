{
 "metadata": {
  "name": "",
  "signature": "sha256:5ec4e9086f735adce1999da5f44cb6118519281536d8a43b6605a1b6bc5453e7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
      "from sklearn.datasets import fetch_20newsgroups\n",
      "import numpy as np\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "\n",
      "import requests\n",
      "from bs4 import BeautifulSoup"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twenty_train = fetch_20newsgroups(subset='train',\n",
      "     shuffle=True, random_state=42)\n",
      "print twenty_train.target_names\n",
      "print len(twenty_train.data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
        "11314\n"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index = 20\n",
      "target_number = twenty_train.target[index]\n",
      "print twenty_train.target_names[target_number]\n",
      "print\n",
      "print(\"\\n\".join(twenty_train.data[index].split(\"\\n\")))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "alt.atheism\n",
        "\n",
        "From: keith@cco.caltech.edu (Keith Allan Schneider)\n",
        "Subject: Re: <<Pompous ass\n",
        "Organization: California Institute of Technology, Pasadena\n",
        "Lines: 16\n",
        "NNTP-Posting-Host: punisher.caltech.edu\n",
        "\n",
        "livesey@solntze.wpd.sgi.com (Jon Livesey) writes:\n",
        "\n",
        "[...]\n",
        ">>The \"`little' things\" above were in reference to Germany, clearly.  People\n",
        ">>said that there were similar things in Germany, but no one could name any.\n",
        ">That's not true.  I gave you two examples.  One was the rather\n",
        ">pevasive anti-semitism in German Christianity well before Hitler\n",
        ">arrived.  The other was the system of social ranks that were used\n",
        ">in Imperail Germany and Austria to distinguish Jews from the rest \n",
        ">of the population.\n",
        "\n",
        "These don't seem like \"little things\" to me.  At least, they are orders\n",
        "worse than the motto.  Do you think that the motto is a \"little thing\"\n",
        "that will lead to worse things?\n",
        "\n",
        "keith\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count_vect = CountVectorizer()\n",
      "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
      "X_train_counts.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 132,
       "text": [
        "(11314, 130107)"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This shows above that we have 130107 distinct words across 11314 documents. We can see how frequently individual words show up in the whole set below. What words do you think show up more often then others?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count_vect.vocabulary_.get(u'science')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 133,
       "text": [
        "105252"
       ]
      }
     ],
     "prompt_number": 133
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above simply counts the number of words in each document. However, bigger documents will have more of every type of word. To normalize this, we run this count a different way that divides the count by the total number of words in each document."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf_transformer = TfidfTransformer()\n",
      "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "        \n",
      "def naive_bayes(X_train_tfidf, twenty_train,docs_new,show_doc=True):\n",
      "    X_new_counts = count_vect.transform(docs_new)\n",
      "    X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
      "    clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)\n",
      "    predicted = clf.predict(X_new_tfidf)\n",
      "\n",
      "    for doc, category in zip(docs_new, predicted):\n",
      "        if show_doc:\n",
      "            print('%r => %s' % (doc, twenty_train.target_names[category]))\n",
      "        else:\n",
      "            print(twenty_train.target_names[category])\n",
      "    return clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "docs_new = ['A home run is a difficult task', 'That convertible is really fast']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Naive Bayes\n",
      "model_naive_bayes = naive_bayes(X_train_tfidf,twenty_train,docs_new)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "'A home run is a difficult task' => rec.sport.baseball\n",
        "'That convertible is really fast' => rec.autos\n"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#url = \"https://en.wikipedia.org/wiki/Digital_electronics\"\n",
      "#url = \"https://en.wikipedia.org/wiki/Hilary_clinton\"\n",
      "#url = \"http://www.carmagazine.co.uk/car-reviews/mazda/mazda-3-2016-review/\"\n",
      "response = requests.get(url)\n",
      "docs_new = [BeautifulSoup(response.text,\"html5lib\").html.text]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_naive_bayes = naive_bayes(X_train_tfidf,twenty_train,docs_new,False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "rec.autos\n"
       ]
      }
     ],
     "prompt_number": 171
    }
   ],
   "metadata": {}
  }
 ]
}